\documentclass[main.tex]{subfiles}
\begin{document}
En sortie de l'égaliseur, on échantillonne le signal reçu. Dans ce chapitre on fera l'hypothèse:
\begin{itemize}
\item d'une synchronisation parfaite entre emission et réception.
\item d'une égalisation parfaite de la chaine de transmission.
\end{itemize}
\section{Taux d'erreur binaire}
Le signa reçu peus se mettre sous la forme :
\[
r(t) = u(t)+ b(t)
\]
avec $b(t)$ brui blanc gaussien.
\begin{defin}
  Le taux d'erreur bianire  (TEB) ou bit errror rate (BER) est défini par :
  \[
    BER = \frac{\text{ nb bit faux }}{\text{nb total bit transmis}}
  \]
\end{defin}
\begin{defin}
  On appelle \emph{taux d'erreur} $\epsilon$la probabilité de prendre une mauvaise décision sur l'information acquise:
  \begin{itemize}
  \item sachant les conditions de bruit ($\sigma^2$ est connu).
  \item en connaissant l'emplacement des seuils de décision.
  \item en connaissant la probabilité d'apparition des symboles.
  \end{itemize}
\end{defin}
\begin{rem}
  Cela permet a priori de connaitre la qualité de la transmission.
  Dans le cas binaire on a $\epsilon = BER$
\end{rem}

\subsection{Exemple d'application}
\subsubsection{cas binaire antipolaire}
Pour une transmission binaire equiprobable ,où :
\begin{itemize}
\item $u(t_0) = +1V$,si le bit transmis est un $1_l$
\item $u(t_0) = -1V$,si le bit transmis est un $0_l$
\item ajout d'un bruit de variance $\sigma^2$.
\end{itemize}
On place le seuil de décision au centre (à $0V$)
La probabilité de faire une erreur est alors:

\[
\epsilon  = P(\text{tx} 0_l).P(\text{rx} 1_l) + P(\text{tx} 1_l).P(\text{rx} 0_l) 
\]
Ce que l'on réecrit :
\[
\epsilon = P(0_l).P(r(t_0)>0)+P(1_l).P(r(t_0)<0)
\]

\begin{align*}
    \varepsilon=& \frac{1}{2} \times \int_{0}^{+\infty} \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(x+\Delta / 2)^{2}}{2 \sigma^{2}}\right) d x \\ &+\frac{1}{2} \times \int_{-\infty}^{0} \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(x-\Delta / 2)^{2}}{2 \sigma^{2}}\right) d x
\end{align*}
\[
  \begin{aligned} \varepsilon &=\frac{1}{2} \int_{\Delta / 2 \sigma}^{+\infty} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{x^{2}}{2}\right) d x+\frac{1}{2} \int_{\Delta / 2 \sigma}^{+\infty} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{x^{2}}{2}\right) d x \\
    &=\int_{\Delta / 2 \sigma}^{+\infty} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{x^{2}}{2}\right)
  \end{aligned}
\]
C'est la fonction de répartition complémentée de la loi normale.

\begin{align*} G_{c}\left(\frac{\Delta}{2 \sigma}\right) &=\int_{\Delta / 2 \sigma}^{+\infty} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{x^{2}}{2}\right) d x \\ &=1-\int_{-\infty}^{\Delta / 2 \sigma} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{(x)^{2}}{2}\right) d x \\ &=1-F\left(\frac{\Delta}{2 \sigma}\right) \end{align*}

\begin{defin}
  Dans les télecom on utlise les fonciton $erf$ et $erfc$
\[
\operatorname{erfc}(x)=\frac{2}{\sqrt{\pi}} \int_{x}^{+\infty} \exp \left(-r^{2}\right) d r=1-\operatorname{erf}(x)
\]
\end{defin}

\begin{rem}
  On a :
  \[
G_{c}(x)=\frac{1}{2} \cdot \operatorname{erfc}\left(\frac{x}{\sqrt{2}}\right)
\]
\end{rem}
\subsubsection{Code m-aire unipolaire}
soit un code $m$-aire unipolaire tel que:
\begin{itemize}
\item écrat entre niveaux uniforme vallant $\Delta$.
\item seuils de décision situés à $\Delta/2$.
\end{itemize}
\[
  \begin{aligned} \varepsilon=& p(0) \cdot \operatorname{prob}\left(u>\frac{\Delta}{2}\right)+p(m-1) \cdot \operatorname{prob}\left(u<-\frac{\Delta}{2}\right) \\ &+\sum_{k=1}^{m-2} p(k) \cdot \operatorname{prob}\left(|u| \geq \frac{\Delta}{2}\right)
  \end{aligned}
\]

avec $p(k)$ probabilité de transmettre le niveau $k$.pour des niveaux
equiprobables:
\[
\varepsilon=\frac{2(m-1)}{m} . G_{c}\left(\frac{\Delta}{2 \sigma}\right)=\frac{(m-1)}{m} \cdot \operatorname{erfc}\left(\frac{\Delta}{2 \sqrt{2} \sigma}\right)
\]

\section{Introduction du rapport signal sur bruit}
\paragraph{Rappel}: La puissance d'un signal aléatoire est:
\[
S=\sum_{k=0}^{m-1} p(k) \cdot a_{k}^{2}
\]
Si tous les niveaux sont équiprobables et pour un écart constants entre
niveaux $\Delta$, on obtient :

\begin{itemize}
\item pour les code $m$-aires unipolaires : $S=\frac{(m-1)(2 m-1)}{6}
  \Delta^{2}$
\item pour les cas antipolaires :
  $S=\frac{m^{2}-1}{12} \Delta^{2}$
\end{itemize}


\begin{prop}
  Avec les calculs précédents on obtient:
  \begin{itemize}
  \item Cas unipolaire :
    \[\varepsilon=\frac{2(m-1)}{m} . G_{c}\left(\sqrt{\frac{3}{2(m-1)(2 m-1)} \cdot \frac{S}{N}}\right)\]
  \item cas antipolaire:
    \[
\varepsilon=\frac{2(m-1)}{m} \cdot G_{C}\left(\sqrt{\frac{3}{m^{2}-1} \cdot \frac{S}{N}}\right)
\]
\item Pour le binaire on a respectivement:
  \[
    \epsilon_b = G_c\left(\sqrt{\frac{S}{2N}}\right) \text{ et } \epsilon_b = G_c\left(\sqrt{\frac{S}{N}}\right)
  \]
  \end{itemize}
\end{prop}
\subsection{Cas d'un mot à $N$ digits}

\begin{prop}
  Soit un sytème de transmission dont le taux moyen d’erreur par élément binaire $\epsilon_b$ , avec lequel on transmet une information à l’aide de mots de longueur n (n digits), on peut dire :
  \begin{itemize}
  \item   que la probabilité pour qu’un élément binaire soit juste est $(1 - \epsilon b )$
  \item que la probabilité que tous les éb du mot, qui sont indépendants, soient justes, donc que le mot n’ait pas d’erreur, est $M(0) = (1 - \epsilon b )^n$ 
  \item que la probabilité pour qu’il n’y ait qu’une erreur (un seul élément binaire faux dans le mot) est $M(1) = n.\epsilon_b .(1 -\epsilon_b)^{n-1}$.
  \item que la probabilité pour qu’il y ait k erreurs dans le mot (k<n) est 
    \[
M(k)=C_{n}^{k} \varepsilon_{b}^{k}\left(1-\varepsilon_{b}\right)^{n-k}
\]
\item que la probabilité pour qu’il y ait au moins une erreur dans le mot est
  \[
M(>0)=1-\left(1-\varepsilon_{b}\right)^{n}\simeq n\epsilon_b
\]
\item que la probabilité pour qu’il y ait plus d’une erreur dans le mot est:
  \[
M(>1)=1-\left(1-\varepsilon_{b}\right)^{n}-n \cdot \varepsilon_{b} \cdot\left(1-\varepsilon_{b}\right)^{n-1}
\]càd tous les cas possible
sauf ceux où il n’y a pas d’erreur et ceux où il n’y a qu’une erreur.
    
    
\end{itemize}
\end{prop}
\section{Filtre adapté (Optimisation du RSB)}
\subsection{Conception du filtre adpaté}

On a vu que le BER est directement lié au RSB. L'objectif du filtre de réception est donc de maximiser le RSB à l'instant de prise de décision, on parle alors de filtre adapté. 
\begin{prop}
  Àl'instant de décision on a :
  \[
    \frac{\mathcal{S}}{\mathcal{N}}= \frac{r^2(t_0+nT)}{E[b^2(t_0+nT)]}
  \]
  \begin{itemize}
  \item $r(t) = g_r(t)\ast s(t) = \int_{-\infty}^{+\infty}g_r(t-\tau)s(\tau)\d \tau$
  \item $b(t) = g_r(t)\ast n(t) $
  \item $n$ un BABG centrée et de variance $\sigma_n$.
  \end{itemize}
\end{prop}

On fait les hypothèses suivantes:
\begin{itemize}
\item L'égaliseur a parfaitement compensé l'effet du canal
\item Le sysytème est parfaitement synchronisé $\implies s(t_0+nT)\simeq g_e(t_0+nT)$
\end{itemize}


\begin{defin}
  \emph{Puissance de bruit}

\[
  \begin{aligned}
    \mathcal{N} &=\int_{-\infty}^{+\infty} \phi_{b b}(f) d f \\ &=\int_{-\infty}^{+\infty}\left|G_{r}(f)\right|^{2} \phi_{n n}(f) d f \\ &=\frac{\sigma_{n}^{2}}{2} \int_{-\infty}^{+\infty}\left|g_{r}(\tau)\right|^{2} d f
  \end{aligned}
\]
\emph{Puissance du signal}
\[
r\left(t_{0}+n T\right)=\int_{-\infty}^{+\infty} g_{e}\left(t_{0}+n T-\tau\right) g_{r}(\tau) d \tau
\]
Puis
\[
\begin{aligned} \mathcal{S}\left(t_{0}+n T\right) &=\left|r\left(t_{0}+n T\right)\right|^{2} \\ &=\left|\int_{-\infty}^{+\infty} g_{e}\left(t_{0}+n T-\tau\right) g_{r}(\tau) d \tau\right|^{2} \\  \end{aligned}
\]
\end{defin}
\begin{prop}
  On  a d'apres l'inégalité de Cauchy-Schwarz:
  \[
 \mathcal{S}\left(t_{0}+n T\right) \leq \int_{-\infty}^{+\infty}\left|g_{e}\left(t_{0}+n T-\tau\right)\right|^{2} d \tau \times \int_{-\infty}^{+\infty}\left|g_{r}(\tau)\right|^{2} d \tau
  \]

  La puissance sera maximale si $g_r(t) =C\times g_e^*(t_0+nT-\tau)$ avec $C$ une constante.On choisit donc cette expression pour le filtre adapté.

  On a le RSB suivant:
  \[
\mathcal{S} / \mathcal{N}=\frac{\int_{-\infty}^{+\infty}\left|g_{e}\left(t_{0}+n T-\tau\right)\right|^{2} d \tau}{\frac{\sigma_{0}^{2}}{2}}
\]
\end{prop}

\subsection{Réalisation du filtre adapté}

On réalise filtre adatpé en réalisatant une corrélation entre $g_e$ et $s$. Tout est très bien expliqué dans le cours de l'UE451.
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
